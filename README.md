# ğŸ“Š Machine Learning Models From Scratch

This project implements several core machine learning algorithms **from scratch** in Python, without using libraries like scikit-learn. It is designed for learning and understanding the inner workings of these models and optimization methods.

---

## ğŸ“‹ Implemented Models

### 1. K-Nearest Neighbors (KNN)
- Simple instance-based learning algorithm.
- Classifies data points based on the majority class of the nearest neighbors.

### 2. Linear Regression
- Predicts continuous values.
- Implemented using the least squares method.
- Supports Mean Squared Error (MSE) calculation.

### 3. Logistic Regression
- Binary classification model.
- Implements sigmoid activation function.
- Supports gradient descent optimization.

### 4. Support Vector Machine (SVM)
- Linear SVM classifier.
- Uses hinge loss and gradient descent optimization.
- Handles binary classification tasks.

### 5. Gradient Descent Variants
- **Batch Gradient Descent (BGD)**: Updates parameters using the entire dataset.
- **Mini-Batch Gradient Descent (MBGD)**: Updates parameters using small batches for faster convergence.
- **Stochastic Gradient Descent (SGD)**: Updates parameters using one sample at a time.
- All variants include learning rate tuning and iteration tracking.

---

## ğŸ› ï¸ Features
- Implemented **from scratch** in Python for educational purposes.
- Supports training, prediction, and evaluation.
- Modular code to easily add new models or optimizers.
- Includes example datasets for testing and visualization.

---

## ğŸš€ Getting Started
1. Clone the repository:
   ```bash
   git clone <repository-url>
